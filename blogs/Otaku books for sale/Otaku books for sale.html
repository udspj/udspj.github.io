<!DOCTYPE html>
<html>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>爬了宅书的数据，另外搞了个展示页</title>

<xmp theme="simplex" style="display:none;">

otaku books for sale
https://udspj.github.io/OtakuBooksDataList

因为淘宝禁止没有经营许可的卖家售卖海外出版物，上次又因我的一本lu点轻小说被淘宝系统查到了直接扣了12分导致被关店7天，不得已只能把店里所有日版的漫画、轻小说、公式书、画集等全部下架放淘宝仓库里。但这样买家来我店铺就看不到我这些宅书了，无奈只能自己另外做一个宅书展示页让买家浏览，我可以随时从商品仓库里帮买家上架想买的东西。

想提取的这些宅书都放在“仓库里的宝贝”中，这个必须店主登录才能看到，所以就还是从淘宝店铺的分类里去提取了。宅书都没上架，先抓“日本原版动漫周边”这个类目里的宅物试试。

![udspj](imgs/img1.png)

由于这块商品列表是动态加载的，得另外找到请求商品列表的地址。

![udspj](imgs/img2.png)

复制地址到浏览器看到也还是个html的形式，url里改变pageNo=＊切换页数。

![udspj](imgs/img3.png)

在这个html源码里找到了商品名称、缩略图、商品详情url、商品价格。

![udspj](imgs/img4.png)

整个页面html源码被包含在jsonp154()里，得先把这层东西去掉。

商品数量是动态的，可以从页面获取到是否已经没有更多数据了。

没数据的页面比有数据的多了一句“很抱歉，搜索到“0”个宝贝”，在源码里找到这句是在唯一一个strong标签里，有数据的页面不含strong标签，所以就拿strong标签来判断是否末尾页。

![udspj](imgs/img5.png)

![udspj](imgs/img6.png)

最终拿到了需要的数据，把所有商品缩略图下载下来，文件名按商品详情url里的id保存。

这些都只是商品列表数据，整理成json格式存为文本。

json文本里有保存所有商品名，有些名字里含有字符“×”乘号的，爬出来的编码是“\xd7”，可能会解析不了，找出这些“\xd7”替换成普通的字母x来代替。

另外还要继续爬商品详情。

![udspj](imgs/img7.png)

顺道保存下代码，随便写的脚本……

```c
#!/usr/bin/python
#coding:utf-8
import requests
from bs4 import BeautifulSoup

pageEnd = False
pageNo = 1
goodList = []

# 下载商品列表信息

while pageEnd == False:
	url = "https://shop36066072.taobao.com/i/asynSearch.htm?_ksTS=1495095535601_153&mid=w-726411589-0&wid=726411589&path=/category-280512636.htm&catId=280512636&scid=280512636&pageNo="+str(pageNo)
	remap = {
	    'jsonp154("                ' : None
	}
	htmltext = requests.get(url).text
	hh = htmltext.replace('jsonp154("                ', '')
	hh2 = hh.replace('\\"', '"')
	soup = BeautifulSoup(hh2, 'html.parser')
	tags = soup.find_all('dt', class_='photo')
	end = soup.find_all('strong')
	if len(end) > 0 :
		pageEnd = True
		break
	startindex = len(goodList)
	for _ in tags: 
		href = 'https:' + _.a['href']
		imgsrc = _.a.img['src']
		title = _.a.img['alt']
		imgurl = requests.get('http:'+imgsrc)
		idstr = href.replace('https://item.taobao.com/item.htm?id=', '')
		string = idstr + '.jpg'
		isFolderExists = os.path.exists('thumbnails/')
		if not isFolderExists:
			os.mkdir('thumbnails/')
		fp = open('thumbnails/'+string,'wb')
		fp.write(imgurl.content)
		fp.close()
		goodList.append({'id':idstr, 'href':href, 'title':title, 'price':''})
	spans = soup.find_all('span', class_='c-price')
	spanindex = startindex
	for _ in spans:
		price = _.text
		goodList[spanindex]['price'] = price
		spanindex = spanindex + 1
	pageNo = pageNo + 1
jsontext = {'data':goodList}
fh = open("json.txt","wb")
fh.write(str(jsontext).replace(' u\'', ' \'').decode("utf-8"))
fh.close()
```

－

商品详情页里需要拿到商品的多张大图。

在详情页源码里直接能找到auctionImages里面就是所有的详情大图的链接了，把这些图分别下载到对应商品id的文件夹里。

![udspj](imgs/img8.png)

在上面代码的基础上增加以下代码用来下载详情图：

```c

……
和上面重复的代码
……

import re
import os

……
和上面重复的代码
……

# 下载商品详情大图

for good in goodList:
	goodid = good['id']
	detailurl = 'https://item.taobao.com/item.htm?id=' + goodid
	htmltext = requests.get(detailurl).text
	pattern = re.compile(r'auctionImages    :(.*?)"]')
	imgsstr = re.search(pattern, htmltext, flags=0).group()
	imgsstr = imgsstr.replace('auctionImages    : [', '')
	imgsstr = imgsstr.replace(']', '')
	imgsstr = imgsstr.replace('"', '')
	imgs = imgsstr.split(',')
	isFolderExists = os.path.exists('images/')
	if not isFolderExists:
		os.mkdir('images/')
	imgfolder = 'images/' + goodid + '/'
	isImgFolderExists = os.path.exists(imgfolder)
	if not isImgFolderExists:
		os.mkdir(imgfolder)
	for _ in imgs:
		imgstrs = _.split('/')
		string = imgstrs[len(imgstrs) - 1]
		fp = open(imgfolder + string,'wb')
		fp.write(requests.get('http:' + _).content)
		fp.close()
```

淘宝商品详情说明不是纯文本而是html格式的，并且是动态获取的数据。

![udspj](imgs/img9.png)

![udspj](imgs/img10.png)

</xmp>

<script src="https://lbesson.bitbucket.io/md/strapdown.min.js"></script>
</html>